benchmarks:
- benchmark_name: ppermute
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 128}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: all_gather
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 128}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: psum
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 128}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: psum_scatter
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 128}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: all_to_all
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 1, ici_size_range: 128}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "naive_matmul"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "single_host_naive_matmul"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "multilayer_collective_matmul"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "collective_matmul_one_direction"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "collective_matmul_two_directions"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "naive_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false, scale: false}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: true}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "pallas_flash_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "splash_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "flax_nnx_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "flax_linen_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "keras_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"

